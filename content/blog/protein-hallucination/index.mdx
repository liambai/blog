---
title: Protein Inception
date: "2023-10-08"
description: Protein design. DeepDrem, hallucinations, Markov Chain Monte Carlo (MCMC), ...
---

import { Link } from "gatsby"
import Figure from "../../../src/components/figure.jsx"
import Image from "../../../src/components/image.jsx"

Models that are good at making predictions also possess some generative power. We saw this theme play out in <Link to="/protein-evolution">previous</Link> <Link to="/protein-representation">posts</Link> with a technique called **Markov Chain Monte Carlo (MCMC)**. Here's a quick recap:

Imagine you have a monkey that, when shown an image, always gets visibly excited if the image contains bananas – and sad otherwise.

<Figure content={<Image path={require("./images/monkey-model.png")} />} />

One obvious task the monkey can help with is image classification, discriminating images with bananas and ones without. The monkey is a _discriminative_ model.

Now suppose you want to create some _new_ images of bananas. We can start with a white-noise image:

<Figure
  content={
    <Image
      path={require("./images/white-noise.png")}
      width="50%"
      mobileWidth="60%"
    />
  }
/>

randomly change a couple pixels, and show it to our monkey:

- If he gets more excited, then we've probably done something that made the image more banana-like. Great – let's keep the changes.
- If he doesn't doesn't get more excited – or god forbid, gets less excited – let's forget about the changes.

Repeat this thousands of times: we'll end up with an image that looks a lot like bananas! This is the essence of MCMC, which lets us turn our monkey into a _generative_ model.

Researchers at Google used a similar technique in a mind-blowing project called [DeepDream](https://en.wikipedia.org/wiki/DeepDream). Instead of monkeys, they used [**convolutional neural networks (CNNs)**](https://en.wikipedia.org/wiki/Convolutional_neural_network).

<Figure content={<Image path={require("./images/deepdream-bananas.png")} />} />

The resulting images have a dream-like quality and are often called **hallucinations**.

Let's replace the banana recognition task with one we're not so good at: predicting the activity of proteins – and designing new ones with desired properties. The ability to do this is revolutionary to industrial biotechnology and therapeutics. In this post, we'll explore how approaches similar to DeepDream can be used to design new proteins.

## The model: trRosetta

### Overview

**transform-restrained Rosetta (trRosetta)** is a structure prediction model that, like pretty much everything we'll talk about in this post, was developed at the [Baker lab](https://www.bakerlab.org/). trRosetta has 2 steps:

1. Given a [Multiple Sequence Alignment (MSA)](https://en.wikipedia.org/wiki/Multiple_sequence_alignment), use a CNN to predict 6 structure-defining numbers _for each pair of amino acid residues_.

2. Use the 6 numbers produced by the CNN as input to the [Rosetta](https://www.rosettacommons.org/software) structure modeling software to generate 3D structures.

Let's focus on step 1. One of the structure-defining numbers is the distance between the residues, $d$. There's also this angle $\omega$:

<Figure
  content={
    <Image
      path={require("./images/interresidue-distance.png")}
      width="40%"
      mobileWidth="60%"
    />
  }
/>

as well as 4 other angles:

<Figure
  content={
    <Image
      path={require("./images/interresidue-angles.png")}
      width="40%"
      mobileWidth="60%"
    />
  }
/>

If we know these 6 numbers for _each_ residue pair in the amino acid chain, then we should have a pretty good sense of the 3D structure, making step 2 possible.

### How it works

Here's the architecture of the trRosetta CNN. For our purposes, understanding the inner workings is not important, and we can just keep in mind that that the network takes in an MSA and spits out these distances and orientation angles.

<Figure
  content={
    <Image
      path={require("./images/trRosetta-architecture.png")}
      width="40%"
      mobileWidth="60%"
    />
  }
/>

### Distance maps

Let's consider the residue pair distances predicted by the network. We can represent them in matrices called **distance maps**, like these:

<Figure
  content={
    <Image
      path={require("./images/distance-map.png")}
      width="60%"
      mobileWidth="80%"
    />
  }
/>

The diagonal of the matrix represents distances of each residue with itself – which are of course 0 – hence the dark diagonal line.

Neural networks output probabilities, not definitive answers. For example, language models like GPT – tasked with predicting the next word given some previous words as context – outputs a probability distribution over the set of all possible words (the vocabulary); in an additional final step, the word with the highest probability is chosen to be the prediction. In our case, trRosetta outputs probabilities for different distance bins, like this:

<table style={{width: 300, margin: "auto"}}>
  <tr>
    <th style={{textAlign: "left"}}>Distance bin</th>
    <th style={{textAlign: "left"}}>Probability</th>
  </tr>
  <tr>
    <td>0 - 0.5 $\text{\r{A}}$</td>
    <td>0.0001</td>
  </tr>
  <tr>
    <td>0.5 - 1 $\text{\r{A}}$</td>
    <td>0.0002</td>
  </tr>
  <tr>
    <td>...</td>
    <td>...</td>
  </tr>
  <tr>
    <td>5 - 5.5 $\text{\r{A}}$</td>
    <td>0.01</td>
  </tr>
  <tr>
    <td>5.5 - 6.0$\text{\r{A}}$</td>
    <td>0.74</td>
  </tr>
  <tr>
    <td>6.0 - 6.5$\text{\r{A}}$</td>
    <td>0.12</td>
  </tr>
  <tr>
    <td>...</td>
    <td>...</td>
  </tr>
  <tr>
    <td>19.5 - 20 $\text{\r{A}}$</td>
    <td>0</td>
  </tr>
</table>
<br />

In this example, it's pretty clear that trRosetta thinks the distance between these two residues should be around 6.0$\text{\r{A}}$, which we can use as our prediction. Because trRosetta is so confident, we can say that the distance map is _sharp_.

However, trRosetta is not always so confident. If the probability distribution is more uniform, then it's not so clear which distance bin is best. In those cases, the distance map is _blurry_.

Let's visualize this. In the two distance maps we showed above, the colors reflect, for each residue pair, the sum of trRosetta's predicted probabilities for the bins in the $ <10 \text{\r{A}}$ range, i.e. how likely trRosetta thinks it is for the residues to end up close together in the 3D structure.

<Figure
  content={
    <Image
      path={require("./images/distance-map.png")}
      width="60%"
      mobileWidth="80%"
    />
  }
/>

The left distance map is blurry, while the right one is sharp.

If we provide trRosetta a garbage sequence that doesn't even encode a stable protein, no matter how good trRosetta is at its job of predicting distances, the distance map will be blurry. After all, how can trRosetta be sure if you're asking for the impossible? Conversely, if we provide good sequences of stable proteins, trRosetta will produce sharp distance maps.

This idea is important because sharpness, like the monkey's excitement for bananas, is a signal that we can lean on to differentiate good sequences from bad ones.

### Quantifying sharpness

(This section has some mathematical details – feel free to skip. TLDR: there's a way to quantify sharpness.)

Leo Tolstoy famously said:

> All happy families are alike; each unhappy family is unhappy in its own way.

For distances maps produced by trRosetta, it's quite the opposite: all blurry distance maps are alike; each sharp distance map is sharp in its own way. Each functional protein has a unique structure – that determines a specific function – something that trRosetta learns to capture, whereas each nonfunctional sequence is kinda the same to trRosetta: a whole lotta garbage.

Without a canonical example of sharpness, perhaps the best way to quantify it is to come up with some blurry distance map $Q$ to steer away from: a distance map is sharp if it's very _different_ from $Q$.

To get $Q$, we can train trRosetta on the same training sequences, except hiding the identity of each amino acid. This retains some rudimentary characteristics of an amino acid chain: each amino acid has distance $0$ to itself (the dark diagonals), residues that are close in sequence are close in space, etc. But it wipes out all information about the interactions between different amino acids.

Given some distance map $P$, how do we measure its similarity to our bad example, $Q$? Remember, a distance map is just a collection of probability distributions, one for each residue pair. If we can measure the difference in the probability distributions at each position – $P_{ij}$ and $Q_{ij}$ – we can average over those measurements and get a measurement between $P$ and $Q$:

$$
D_{\text{map}}(P, Q) = \frac{1}{L^2} \sum_{i, j = 1}^L D_{\text{distribution}}(P_{ij}, Q_{ij})
$$

where $L$ is the length of the sequence, $D_{\text{map}}$ measures similarity between distance maps, and $D_{\text{distribution}}$ measures similarity between probability distributions.

Here's one way to measure the similarity between two distributions:

$$
D_{\text{distribution}}(P_{ij}, Q_{ij}) = \sum_{x \in \text{bins}} P_{ij}^{(x)} \log \left(\frac{P_{ij}^{(x)}}{Q_{ij}^{(x)}}\right)
$$

This $D_{\text{distribution}}$ is called the **Kullback–Leibler (KL) divergence**, which came from [information theory](https://en.wikipedia.org/wiki/Information_theory). It's a common [loss function](https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html) in machine learning. (Note on notation: it's conventional to use double bars like $D_{KL}(P || Q)$ to emphasize the fact that $D_{KL}(P || Q) \neq D_{KL}(Q || P)$, i.e. KL divergence is not a true distance metric.)

To summarize, we have developed a way to quantify the sharpness of a distance map $P$. Rewriting the notation to be consistent with [this paper](https://www.nature.com/articles/s41586-021-04184-w):

$$
D_{KL}(P || Q) = \frac{1}{L^2} \sum_{i, j = 1}^L \sum_{x \in \text{bins}} P_{ij}^{(x)} \log \left(\frac{P_{ij}^{(x)}}{Q_{ij}^{(x)}}\right)
$$

Intuitively, $P$ is sharp if its as far away from $Q$ as possible, as measured by the average KL divergence.

## Hallucinating proteins

## Can we do better than random?
